{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install kshape\n",
    "pip install tslearn\n",
    " pip install hdbscan --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Main'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip, datetime\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "\n",
    "'''Data Viz'''\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "'''Data Prep and Model Evaluation'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import random\n",
    "\n",
    "'''Algos'''\n",
    "from kshape.core import kshape, zscore\n",
    "import tslearn\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.clustering import KShape, TimeSeriesKMeans\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "#current_path = os.getcwd()\n",
    "#file = os.path.sep.join(['', 'datasets', 'ucr_time_series_data', ''])\n",
    "\n",
    "data_train = np.loadtxt(\"train_trans.csv\", delimiter=',')\n",
    "X_train = to_time_series_dataset(data_train[:, 1:])\n",
    "y_train = data_train[:, 0].astype(np.int)\n",
    "\n",
    "data_test = np.loadtxt(\"test_trans.csv\", delimiter=',')\n",
    "X_test = to_time_series_dataset(data_test[:, 1:])\n",
    "y_test = data_test[:, 0].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time series: 137\n",
      "Number of unique classes: 73\n",
      "Time series length: 22\n"
     ]
    }
   ],
   "source": [
    "# Basic summary statistics\n",
    "print(\"Number of time series:\", len(data_train))\n",
    "print(\"Number of unique classes:\", len(np.unique(data_train[:,0])))\n",
    "print(\"Time series length:\", len(data_train[0,1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
