{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flare\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flare\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\flare\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  validation loss: 0.17248419\n",
      "epoch: 1  validation loss: 0.17304894\n",
      "epoch: 2  validation loss: 0.17316653\n",
      "epoch: 3  validation loss: 0.17285866\n",
      "epoch: 4  validation loss: 0.17204347\n",
      "epoch: 5  validation loss: 0.1720529\n",
      "epoch: 6  validation loss: 0.17250098\n",
      "epoch: 7  validation loss: 0.17458053\n",
      "epoch: 8  validation loss: 0.17207702\n",
      "epoch: 9  validation loss: 0.17202564\n",
      "epoch: 10  validation loss: 0.17260167\n",
      "epoch: 11  validation loss: 0.17246771\n",
      "epoch: 12  validation loss: 0.17204009\n",
      "epoch: 13  validation loss: 0.17415231\n",
      "epoch: 14  validation loss: 0.17210627\n",
      "epoch: 15  validation loss: 0.17318684\n",
      "epoch: 16  validation loss: 0.17461717\n",
      "epoch: 17  validation loss: 0.1723949\n",
      "epoch: 18  validation loss: 0.17203417\n",
      "epoch: 19  validation loss: 0.17395937\n",
      "epoch: 20  validation loss: 0.17327218\n",
      "epoch: 21  validation loss: 0.17231917\n",
      "epoch: 22  validation loss: 0.17267078\n",
      "epoch: 23  validation loss: 0.17202546\n",
      "epoch: 24  validation loss: 0.17246737\n",
      "epoch: 25  validation loss: 0.172372\n",
      "epoch: 26  validation loss: 0.17338736\n",
      "epoch: 27  validation loss: 0.17320196\n",
      "epoch: 28  validation loss: 0.17201184\n",
      "epoch: 29  validation loss: 0.17329068\n",
      "epoch: 30  validation loss: 0.17385587\n",
      "epoch: 31  validation loss: 0.17442541\n",
      "epoch: 32  validation loss: 0.17274353\n",
      "epoch: 33  validation loss: 0.17353666\n",
      "epoch: 34  validation loss: 0.17232724\n",
      "epoch: 35  validation loss: 0.17287238\n",
      "epoch: 36  validation loss: 0.17212562\n",
      "epoch: 37  validation loss: 0.17295185\n",
      "epoch: 38  validation loss: 0.17235674\n",
      "epoch: 39  validation loss: 0.17368872\n",
      "epoch: 40  validation loss: 0.172276\n",
      "epoch: 41  validation loss: 0.17275509\n",
      "epoch: 42  validation loss: 0.17320886\n",
      "epoch: 43  validation loss: 0.17229123\n",
      "epoch: 44  validation loss: 0.17319143\n",
      "epoch: 45  validation loss: 0.17282474\n",
      "epoch: 46  validation loss: 0.17199372\n",
      "epoch: 47  validation loss: 0.1733382\n",
      "epoch: 48  validation loss: 0.17261504\n",
      "epoch: 49  validation loss: 0.17221521\n",
      "epoch: 50  validation loss: 0.17294341\n",
      "epoch: 51  validation loss: 0.17308056\n",
      "epoch: 52  validation loss: 0.17244056\n",
      "epoch: 53  validation loss: 0.17258488\n",
      "epoch: 54  validation loss: 0.17200895\n",
      "epoch: 55  validation loss: 0.1735447\n",
      "epoch: 56  validation loss: 0.17222083\n",
      "epoch: 57  validation loss: 0.17271332\n",
      "epoch: 58  validation loss: 0.17203833\n",
      "epoch: 59  validation loss: 0.1729996\n",
      "epoch: 60  validation loss: 0.17371894\n",
      "epoch: 61  validation loss: 0.17283833\n",
      "epoch: 62  validation loss: 0.17203088\n",
      "epoch: 63  validation loss: 0.17513873\n",
      "epoch: 64  validation loss: 0.17204407\n",
      "epoch: 65  validation loss: 0.17233756\n",
      "epoch: 66  validation loss: 0.17204712\n",
      "epoch: 67  validation loss: 0.17211631\n",
      "epoch: 68  validation loss: 0.17220251\n",
      "epoch: 69  validation loss: 0.17204602\n",
      "epoch: 70  validation loss: 0.17235288\n",
      "epoch: 71  validation loss: 0.1727019\n",
      "epoch: 72  validation loss: 0.17256299\n",
      "epoch: 73  validation loss: 0.17205618\n",
      "epoch: 74  validation loss: 0.1720874\n",
      "epoch: 75  validation loss: 0.1733161\n",
      "epoch: 76  validation loss: 0.17206608\n",
      "epoch: 77  validation loss: 0.1721953\n",
      "epoch: 78  validation loss: 0.17217144\n",
      "epoch: 79  validation loss: 0.17361508\n",
      "epoch: 80  validation loss: 0.17249484\n",
      "epoch: 81  validation loss: 0.1726007\n",
      "epoch: 82  validation loss: 0.17217764\n",
      "epoch: 83  validation loss: 0.17235047\n",
      "epoch: 84  validation loss: 0.17220218\n",
      "epoch: 85  validation loss: 0.17313005\n",
      "epoch: 86  validation loss: 0.17321385\n",
      "epoch: 87  validation loss: 0.17286782\n",
      "epoch: 88  validation loss: 0.17296784\n",
      "epoch: 89  validation loss: 0.17247303\n",
      "epoch: 90  validation loss: 0.17228664\n",
      "epoch: 91  validation loss: 0.17235993\n",
      "epoch: 92  validation loss: 0.1722953\n",
      "epoch: 93  validation loss: 0.17233624\n",
      "epoch: 94  validation loss: 0.17236891\n",
      "epoch: 95  validation loss: 0.17250088\n",
      "epoch: 96  validation loss: 0.1725937\n",
      "epoch: 97  validation loss: 0.17234305\n",
      "epoch: 98  validation loss: 0.17303193\n",
      "epoch: 99  validation loss: 0.17243783\n",
      "epoch: 100  validation loss: 0.17239277\n",
      "epoch: 101  validation loss: 0.17523585\n",
      "epoch: 102  validation loss: 0.17247762\n",
      "epoch: 103  validation loss: 0.17250201\n",
      "epoch: 104  validation loss: 0.17326397\n",
      "epoch: 105  validation loss: 0.17253532\n",
      "epoch: 106  validation loss: 0.1730546\n",
      "epoch: 107  validation loss: 0.17417331\n",
      "epoch: 108  validation loss: 0.17255594\n",
      "epoch: 109  validation loss: 0.17421044\n",
      "epoch: 110  validation loss: 0.17208087\n",
      "epoch: 111  validation loss: 0.17216401\n",
      "epoch: 112  validation loss: 0.17227097\n",
      "epoch: 113  validation loss: 0.17236753\n",
      "epoch: 114  validation loss: 0.17236513\n",
      "epoch: 115  validation loss: 0.17288658\n",
      "epoch: 116  validation loss: 0.17260431\n",
      "epoch: 117  validation loss: 0.17211701\n",
      "epoch: 118  validation loss: 0.17243278\n",
      "epoch: 119  validation loss: 0.17405018\n",
      "epoch: 120  validation loss: 0.17265297\n",
      "epoch: 121  validation loss: 0.17224371\n",
      "epoch: 122  validation loss: 0.17219128\n",
      "epoch: 123  validation loss: 0.17327163\n",
      "epoch: 124  validation loss: 0.17221722\n",
      "epoch: 125  validation loss: 0.17225595\n",
      "epoch: 126  validation loss: 0.172491\n",
      "epoch: 127  validation loss: 0.17218222\n",
      "epoch: 128  validation loss: 0.17280707\n",
      "epoch: 129  validation loss: 0.17215867\n",
      "epoch: 130  validation loss: 0.17316984\n",
      "epoch: 131  validation loss: 0.17419958\n",
      "epoch: 132  validation loss: 0.17315212\n",
      "epoch: 133  validation loss: 0.17419952\n",
      "epoch: 134  validation loss: 0.17243172\n",
      "epoch: 135  validation loss: 0.17261766\n",
      "epoch: 136  validation loss: 0.17211987\n",
      "epoch: 137  validation loss: 0.17263675\n",
      "epoch: 138  validation loss: 0.17232004\n",
      "epoch: 139  validation loss: 0.17218938\n",
      "epoch: 140  validation loss: 0.17318761\n",
      "epoch: 141  validation loss: 0.17248462\n",
      "epoch: 142  validation loss: 0.17242706\n",
      "epoch: 143  validation loss: 0.17238064\n",
      "epoch: 144  validation loss: 0.17301778\n",
      "epoch: 145  validation loss: 0.17331657\n",
      "epoch: 146  validation loss: 0.17230988\n",
      "epoch: 147  validation loss: 0.17328839\n",
      "epoch: 148  validation loss: 0.17375168\n",
      "epoch: 149  validation loss: 0.17226237\n",
      "epoch: 150  validation loss: 0.17237942\n",
      "epoch: 151  validation loss: 0.17219506\n",
      "epoch: 152  validation loss: 0.17227525\n",
      "epoch: 153  validation loss: 0.17230964\n",
      "epoch: 154  validation loss: 0.17139502\n",
      "epoch: 155  validation loss: 0.17292221\n",
      "epoch: 156  validation loss: 0.1723533\n",
      "epoch: 157  validation loss: 0.17225836\n",
      "epoch: 158  validation loss: 0.17208056\n",
      "epoch: 159  validation loss: 0.17228995\n",
      "epoch: 160  validation loss: 0.17210224\n",
      "epoch: 161  validation loss: 0.17240821\n",
      "epoch: 162  validation loss: 0.17182903\n",
      "epoch: 163  validation loss: 0.17211063\n",
      "epoch: 164  validation loss: 0.17192453\n",
      "epoch: 165  validation loss: 0.17198758\n",
      "epoch: 166  validation loss: 0.17180137\n",
      "epoch: 167  validation loss: 0.17193109\n",
      "epoch: 168  validation loss: 0.17198235\n",
      "epoch: 169  validation loss: 0.17243983\n",
      "epoch: 170  validation loss: 0.17250137\n",
      "epoch: 171  validation loss: 0.13644196\n",
      "epoch: 172  validation loss: 0.011471177\n",
      "epoch: 173  validation loss: 0.005221489\n",
      "epoch: 174  validation loss: 0.003832289\n",
      "epoch: 175  validation loss: 0.0037281488\n",
      "epoch: 176  validation loss: 0.0029787864\n",
      "epoch: 177  validation loss: 0.0028620246\n",
      "epoch: 178  validation loss: 0.0026201338\n",
      "epoch: 179  validation loss: 0.0021442457\n",
      "epoch: 180  validation loss: 0.0022232472\n",
      "epoch: 181  validation loss: 0.0020744943\n",
      "epoch: 182  validation loss: 0.0022799014\n",
      "epoch: 183  validation loss: 0.0017302737\n",
      "epoch: 184  validation loss: 0.0016156209\n",
      "epoch: 185  validation loss: 0.0014911137\n",
      "epoch: 186  validation loss: 0.0013736739\n",
      "epoch: 187  validation loss: 0.001321108\n",
      "epoch: 188  validation loss: 0.0014703656\n",
      "epoch: 189  validation loss: 0.0012023043\n",
      "epoch: 190  validation loss: 0.0014509025\n",
      "epoch: 191  validation loss: 0.0016450392\n",
      "epoch: 192  validation loss: 0.0018712598\n",
      "epoch: 193  validation loss: 0.0010874064\n",
      "epoch: 194  validation loss: 0.0008997306\n",
      "epoch: 195  validation loss: 0.001174005\n",
      "epoch: 196  validation loss: 0.00079865183\n",
      "epoch: 197  validation loss: 0.0011593077\n",
      "epoch: 198  validation loss: 0.0012852111\n",
      "epoch: 199  validation loss: 0.00070496736\n",
      "epoch: 200  validation loss: 0.00077845965\n",
      "epoch: 201  validation loss: 0.00066011987\n",
      "epoch: 202  validation loss: 0.0006389818\n",
      "epoch: 203  validation loss: 0.0007918577\n",
      "epoch: 204  validation loss: 0.0005961982\n",
      "epoch: 205  validation loss: 0.0005435467\n",
      "epoch: 206  validation loss: 0.00056982087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 207  validation loss: 0.000613463\n",
      "epoch: 208  validation loss: 0.0004982586\n",
      "epoch: 209  validation loss: 0.0005868737\n",
      "epoch: 210  validation loss: 0.000597162\n",
      "epoch: 211  validation loss: 0.00046230512\n",
      "epoch: 212  validation loss: 0.00042658224\n",
      "epoch: 213  validation loss: 0.00055070623\n",
      "epoch: 214  validation loss: 0.0007062372\n",
      "epoch: 215  validation loss: 0.00097492454\n",
      "epoch: 216  validation loss: 0.0004173805\n",
      "epoch: 217  validation loss: 0.0003975665\n",
      "epoch: 218  validation loss: 0.00040149456\n",
      "epoch: 219  validation loss: 0.00031516995\n",
      "epoch: 220  validation loss: 0.0005520089\n",
      "epoch: 221  validation loss: 0.0005364204\n",
      "epoch: 222  validation loss: 0.00028228748\n",
      "epoch: 223  validation loss: 0.00032286733\n",
      "epoch: 224  validation loss: 0.00027805593\n",
      "epoch: 225  validation loss: 0.00032458288\n",
      "epoch: 226  validation loss: 0.0003330592\n",
      "epoch: 227  validation loss: 0.0006512767\n",
      "epoch: 228  validation loss: 0.00022921638\n",
      "epoch: 229  validation loss: 0.00022925073\n",
      "epoch: 230  validation loss: 0.00023179842\n",
      "epoch: 231  validation loss: 0.00032625892\n",
      "epoch: 232  validation loss: 0.00020994744\n",
      "epoch: 233  validation loss: 0.00019689949\n",
      "epoch: 234  validation loss: 0.00027878553\n",
      "epoch: 235  validation loss: 0.0002378055\n",
      "epoch: 236  validation loss: 0.00024157278\n",
      "epoch: 237  validation loss: 0.0002251805\n",
      "epoch: 238  validation loss: 0.00019354408\n",
      "epoch: 239  validation loss: 0.00015385005\n",
      "epoch: 240  validation loss: 0.0003564869\n",
      "epoch: 241  validation loss: 0.00023296717\n",
      "epoch: 242  validation loss: 0.00015922869\n",
      "epoch: 243  validation loss: 0.00015251909\n",
      "epoch: 244  validation loss: 0.0002279122\n",
      "epoch: 245  validation loss: 0.00028160022\n",
      "epoch: 246  validation loss: 0.00014352024\n",
      "epoch: 247  validation loss: 0.00012432561\n",
      "epoch: 248  validation loss: 0.0002155992\n",
      "epoch: 249  validation loss: 0.00045640316\n",
      "epoch: 250  validation loss: 0.00018546922\n",
      "epoch: 251  validation loss: 0.00011422387\n",
      "epoch: 252  validation loss: 0.0001281476\n",
      "epoch: 253  validation loss: 0.00060275564\n",
      "epoch: 254  validation loss: 0.00013803926\n",
      "epoch: 255  validation loss: 9.202145e-05\n",
      "epoch: 256  validation loss: 9.366876e-05\n",
      "epoch: 257  validation loss: 9.883356e-05\n",
      "epoch: 258  validation loss: 0.00011517126\n",
      "epoch: 259  validation loss: 0.00021357911\n",
      "epoch: 260  validation loss: 0.00033058188\n",
      "epoch: 261  validation loss: 8.36875e-05\n",
      "epoch: 262  validation loss: 0.00030594078\n",
      "epoch: 263  validation loss: 0.00012207599\n",
      "epoch: 264  validation loss: 9.157119e-05\n",
      "epoch: 265  validation loss: 9.5532756e-05\n",
      "epoch: 266  validation loss: 8.6757085e-05\n",
      "epoch: 267  validation loss: 8.709312e-05\n",
      "epoch: 268  validation loss: 0.00012957654\n",
      "epoch: 269  validation loss: 6.642818e-05\n",
      "epoch: 270  validation loss: 9.3887764e-05\n",
      "epoch: 271  validation loss: 5.4695913e-05\n",
      "epoch: 272  validation loss: 5.4914395e-05\n",
      "epoch: 273  validation loss: 6.8296096e-05\n",
      "epoch: 274  validation loss: 0.00011408481\n",
      "epoch: 275  validation loss: 4.9153405e-05\n",
      "epoch: 276  validation loss: 0.00016931091\n",
      "epoch: 277  validation loss: 5.560641e-05\n",
      "epoch: 278  validation loss: 8.263549e-05\n",
      "epoch: 279  validation loss: 0.000107449145\n",
      "epoch: 280  validation loss: 8.1394974e-05\n",
      "epoch: 281  validation loss: 5.8763697e-05\n",
      "epoch: 282  validation loss: 0.00014858239\n",
      "epoch: 283  validation loss: 5.6272544e-05\n",
      "epoch: 284  validation loss: 0.00020401206\n",
      "epoch: 285  validation loss: 4.757353e-05\n",
      "epoch: 286  validation loss: 4.6647237e-05\n",
      "epoch: 287  validation loss: 6.154105e-05\n",
      "epoch: 288  validation loss: 8.165373e-05\n",
      "epoch: 289  validation loss: 5.9254227e-05\n",
      "epoch: 290  validation loss: 4.103443e-05\n",
      "epoch: 291  validation loss: 0.00021807403\n",
      "epoch: 292  validation loss: 4.0353865e-05\n",
      "epoch: 293  validation loss: 0.00021522472\n",
      "epoch: 294  validation loss: 5.3474494e-05\n",
      "epoch: 295  validation loss: 4.4809945e-05\n",
      "epoch: 296  validation loss: 5.084614e-05\n",
      "epoch: 297  validation loss: 0.00013531926\n",
      "epoch: 298  validation loss: 5.7555808e-05\n",
      "epoch: 299  validation loss: 0.00011293259\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "def inference(x, n_batch, maxlen=None, n_hidden=None, n_out=None):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.compat.v1.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.compat.v1.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.zeros(shape, dtype=tf.float32)\n",
    "        return tf.compat.v1.Variable(initial)\n",
    "\n",
    "    cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    initial_state = cell.zero_state(n_batch, tf.float32)\n",
    "\n",
    "    state = initial_state\n",
    "    outputs = []  # 過去の隠れ層の出力を保存\n",
    "    with tf.compat.v1.variable_scope('LSTM'):\n",
    "        for t in range(maxlen):\n",
    "            if t > 0:\n",
    "                tf.compat.v1.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(x[:, t, :], state)\n",
    "            outputs.append(cell_output)\n",
    "\n",
    "    output = outputs[-1]\n",
    "\n",
    "    V = weight_variable([n_hidden, n_out])\n",
    "    c = bias_variable([n_out])\n",
    "    y = tf.matmul(output, V) + c  # 線形活性\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def loss(y, t):\n",
    "    mse = tf.reduce_mean(tf.square(y - t))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def training(loss):\n",
    "    optimizer = \\\n",
    "        tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n",
    "\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    def mask(T=200):\n",
    "        mask = np.zeros(T)\n",
    "        indices = np.random.permutation(np.arange(T))[:2]\n",
    "        mask[indices] = 1\n",
    "        return mask\n",
    "\n",
    "    def toy_problem(N=10, T=200):\n",
    "        signals = np.random.uniform(low=0.0, high=1.0, size=(N, T))\n",
    "        masks = np.zeros((N, T))\n",
    "        for i in range(N):\n",
    "            masks[i] = mask(T)\n",
    "\n",
    "        data = np.zeros((N, T, 2))\n",
    "        data[:, :, 0] = signals[:]\n",
    "        data[:, :, 1] = masks[:]\n",
    "        target = (signals * masks).sum(axis=1).reshape(N, 1)\n",
    "\n",
    "        return (data, target)\n",
    "\n",
    "    '''\n",
    "    データの生成\n",
    "    '''\n",
    "    N = 10000\n",
    "    T = 200\n",
    "    maxlen = T\n",
    "\n",
    "    X, Y = toy_problem(N=N, T=T)\n",
    "\n",
    "    N_train = int(N * 0.9)\n",
    "    N_validation = N - N_train\n",
    "\n",
    "    X_train, X_validation, Y_train, Y_validation = \\\n",
    "        train_test_split(X, Y, test_size=N_validation)\n",
    "\n",
    "    '''\n",
    "    モデル設定\n",
    "    '''\n",
    "    n_in = len(X[0][0])  # 2\n",
    "    n_hidden = 100\n",
    "    n_out = len(Y[0])  # 1\n",
    "\n",
    "    x = tf.compat.v1.placeholder(tf.float32, shape=[None, maxlen, n_in])\n",
    "    t = tf.compat.v1.placeholder(tf.float32, shape=[None, n_out])\n",
    "    n_batch = tf.compat.v1.placeholder(tf.int32, shape=[])\n",
    "\n",
    "    y = inference(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out=n_out)\n",
    "    loss = loss(y, t)\n",
    "    train_step = training(loss)\n",
    "\n",
    "    history = {\n",
    "        'val_loss': []\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    モデル学習\n",
    "    '''\n",
    "    epochs = 300\n",
    "    batch_size = 100\n",
    "\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    n_batches = N_train // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            sess.run(train_step, feed_dict={\n",
    "                x: X_[start:end],\n",
    "                t: Y_[start:end],\n",
    "                n_batch: batch_size\n",
    "            })\n",
    "\n",
    "        # 検証データを用いた評価\n",
    "        val_loss = loss.eval(session=sess, feed_dict={\n",
    "            x: X_validation,\n",
    "            t: Y_validation,\n",
    "            n_batch: N_validation\n",
    "        })\n",
    "\n",
    "        history['val_loss'].append(val_loss)\n",
    "        print('epoch:', epoch,\n",
    "              ' validation loss:', val_loss)\n",
    "\n",
    "    '''\n",
    "    学習の進み具合を可視化\n",
    "    '''\n",
    "    loss = history['val_loss']\n",
    "\n",
    "    plt.rc('font', family='serif')\n",
    "    fig = plt.figure()\n",
    "    plt.plot(range(len(loss)), loss, label='loss', color='black')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
